# SMART PREDICT

*Next Word Prediction using LSTM RNN*

## ðŸ“Œ Project Objective

The project aims to develop a deep learning model that can **predict the next word** in a given sequence of words.
We have used **LSTM (Long Short-Term Memory)** â€” a type of Recurrent Neural Network (RNN) â€” which is well-suited for sequence prediction tasks.
Also used **GRU RNN** for better accuracy.

**Example:**

```
Input: I am a good  
Output: [predicted word]
```

## ðŸ“‚ Dataset

* **Dataset Name**: *Shakespeareâ€™s Hamlet*
* **Source**: Inbuilt in the **`Gutenberg`** corpus from the **NLTK** library

## ðŸ§¾ Input/Output Data

* **Input**: Text sequences ( previous words )
* **Output**: Predicted next word
* **Type**: Multi-class Classification
  â†’ Because any word from the vocabulary could be the output

## âš™ï¸ Project Pipeline

```bash
Data Collection
   â†“
Data Preprocessing
   â†“
Model Building (LSTM RNN)
   â†“
Model Training
   â†“
Streamlit Web App
   â†“
Deployment
```

## ðŸ§  Model Highlights

* Sequence tokenization and padding
* Embedding Layer ( text -> vectors )
* LSTM layer to capture context from sequences
* Dense output layer with softmax activation
* Trained for multiple epochs using categorical crossentropy

## ðŸ§ª Technologies Used

* TensorFlow and Keras
* NLTK
* Streamlit ( for building the web app and deployment )

## ðŸš€ Deployment

The model is wrapped in a **Streamlit Web App** for interactive next-word predictions.

